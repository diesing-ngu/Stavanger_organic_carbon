---
title: "Modelling"
output: html_notebook
---

# Preparations

## Install packages

```{r packages, message=FALSE, warning=FALSE}
if(!require("pacman")) install.packages("pacman"); library(pacman)
p_load(here,
       sf,
       terra,
       dplyr,
       twosamples,
       caret,
       quantregForest,
       ModelMetrics,
       ggplot2,
       forcats,
       CAST,
       doParallel)
```


## Load required data

```{r load_data}
rm_resp <- read.csv(here("oc_stocks", "data", "interim", "rm_resp.csv"))
resp <- read_sf(here("oc_stocks", "data", "interim", "resp.shp"))
predictors <- rast(here("oc_stocks", "data", "interim", "predictors_aoi.tif"))
AoI <- read_sf(here("oc_stocks", "data", "interim", "AoI.shp"))
```


# Modelling

## K-nearest neighbour distance matching

```{r nndm}
knndmfolds <- knndm(tpoints = resp,
                    modeldomain = AoI,
                    k = 10,
                    samplesize = 2000)
```


## Plot geographic distances

```{r geodist_plot, message=FALSE}
dist_geogr <- geodist(resp, 
                      AoI, 
                      type = "geo",
                      cvfolds = knndmfolds$indx_test,
                      cvtrain = knndmfolds$indx_train,
                      )

p <- plot(dist_geogr, unit = "km")
p

jpeg(filename = here("oc_stocks", "figures", "geodist_plot2.jpg"), width = 15, height = 10, units = "cm", res = 300)
p
dev.off()
```


## Model tuning

A Quantile Regression Forest model is tuned. Predictor variables are selected in a forward feature selection approach and various values of the mtry parameter are tested in a spatial k-fold cross validation.

The maximum number of iterations can be calculated upfront, based on the number of pre-selected predictors:

```{r max_iter}
factorial(nlyr(predictors))/(factorial(2)*factorial(nlyr(predictors)-2)) + sum(c((nlyr(predictors)-2):1))
```


### Forward feature selection

The best combination of predictor variables (features) is found in a forward feature selection process.

*Note: The index is commented out, meaning that knndm is not applied. This was reasonable, as the sampling design gave a randomly distributed dataset (see geographic distance plots).*

```{r ffs, message=FALSE, warning=FALSE}
nCores <- detectCores()
cl <- makePSOCKcluster(nCores - 1)
registerDoParallel(cl)

set.seed(42)

model <- ffs(rm_resp[,names(predictors)],
               rm_resp$OCS_kg_m2,
               method="qrf",
               what = 0.5,
               replace = FALSE,
               importance = TRUE,
               trControl = trainControl(method = "CV",
                                        number = 10,
                                        savePredictions = "final",
                                        #index = knndmfolds$indx_train,
                                        allowParallel = TRUE),
               verbose = FALSE)

stopCluster(cl)

model

sel_preds <- model$selectedvars
```


### FFS plot

Plot of RMSE over the model runs.

```{r ffs_plot, warning=FALSE}
plot(model)
```


## Validation statistics

The validation results of the optimal QRF model.

Note that these are the statistics based on the predicted values of the selected model. These differ from the values from the tuning (above), which are the means of the k predictions based on the folds.

```{r validation_stats}
t <- data.frame(model$pred$pred, model$pred$obs)

validation <- data.frame(me=numeric(), rmse=numeric(), r2=numeric())
validation[1,1] <- round(sum(t$model.pred.obs - t$model.pred.pred)/nrow(t), 3)
validation[1,2] <- round(rmse(t$model.pred.obs, t$model.pred.pred), 3)
validation[1,3] <- round(cor(t$model.pred.obs, t$model.pred.pred)^2, 3)

colnames(validation) <- c("ME", "RMSE", "r2")
rownames(validation) <- NULL
validation
```


## Validation plot

```{r validation_plot, message=FALSE}
val_plot <- ggplot(t, aes(x = model.pred.pred, y = model.pred.obs)) +
            geom_point() +
            geom_smooth(method = "lm") +
            geom_abline(intercept = 0, slope = 1, colour = "grey", linewidth = 1.2) +
            scale_fill_continuous(type = "viridis") +
            theme_bw() +
            scale_x_continuous(name = "Predicted value") +
            scale_y_continuous(name = "Observed value") +
            ggtitle("Organic carbon stock")

val_plot

jpeg(filename = here("oc_stocks", "figures", "validation_plot_ocs.jpg"), width = 15, height = 10, units = "cm", res = 300)
val_plot
dev.off()
```


## Variable importance

```{r variable_importance_plot, warning=FALSE}
imp <- varImp(model$finalModel, scale = FALSE)
imp$Predictor <- rownames(imp)
rownames(imp) <- NULL
imp <- imp[order(imp[1], decreasing = TRUE), c(2, 1)]
colnames(imp)[2] <- "IncMSE"
imp

impfig <- imp %>%
  mutate(Predictor = fct_reorder(Predictor, IncMSE)) %>%
  ggplot( aes(x=Predictor, y=IncMSE)) +
    geom_bar(stat="identity", fill="#f68060", alpha=.6, width=.4) +
    coord_flip() +
    xlab("") +
    ylab("% increase in MSE") +
    theme_bw()
    
impfig
```


## Partial dependence

Partial dependence plots give a graphical depiction of the marginal effect of a variable on the response.

```{r partial_plots}
m2 <- model$finalModel
class(m2) <- "randomForest"

for (i in 1:length(sel_preds)) {
  partialPlot(x = m2, pred.data = rm_resp[sel_preds], x.var = sel_preds[i], main = "", xlab = sel_preds[i], ylab = "OC stock (kg m^2)")
}

```


# Predict QRF model

## Predict the response variable

*Needs to be eventually fixed: Predictions are based on raster package.*

```{r predict_response, message=FALSE, warning=FALSE}
preds <- raster::stack(predictors[[sel_preds]])
OCS_median <- rast(predict(preds, model$finalModel, what = 0.5))
OCS_p95 <- rast(predict(preds, model$finalModel, what = 0.95))
OCS_p5 <- rast(predict(preds, model$finalModel, what = 0.05))
OCS_pi90 <- OCS_p95 - OCS_p5
OCS_pir <- OCS_pi90 / OCS_median
```


## Histogram of predicted organic carbon stocks

```{r hist_ocs}
hist(OCS_median, breaks = 20, main ="", xlab = "Predicted organic carbon stock (kg/m^2)")

jpeg(filename = here("oc_stocks", "figures", "histogram_ocs_pred.jpg"), width = 15, height = 10, units = "cm", res = 300)
hist(OCS_median, breaks = 20, main ="", xlab = "Predicted organic carbon stock (kg/m^2)")
dev.off()
```


## Area of applicability

*Note: CVtest and CVtrain are commented out, as knndm was not applied.*

```{r aoa, warning=FALSE}
OCS_trainDI <- trainDI(model = model,
                       variables = sel_preds,
                       #CVtest = knndmfolds$indx_test,
                       #CVtrain = knndmfolds$indx_train
                       )

print(OCS_trainDI)

OCS_aoa <- aoa(newdata = predictors, 
                model = model,
                trainDI = OCS_trainDI,
                variables = sel_preds,
)

plot(OCS_aoa)


fr <- freq(OCS_aoa$AOA)
print(paste0("AOA = ", round(100*fr$count[2]/ sum(fr$count),2), "% of pixels"))
```


## Plot results

```{r plot_results}
plot(OCS_median, main = "OCS median")
plot(OCS_pi90, main = "90% prediction interval")
plot(OCS_pir, main = "Prediction interval ratio")
plot(OCS_aoa$DI, main = "Dissimilarity index")
plot(OCS_aoa$AOA, main = "Area of applicability")
```


## Convert AOA from raster to polygon

```{r aoa_poly}
aoa_poly <- as.polygons(OCS_aoa$AOA, dissolve = TRUE)
plot(aoa_poly)

write_sf(st_as_sf(aoa_poly), dsn = here("oc_stocks", "data", "ready"), layer = "OCS_aoa", driver = "ESRI Shapefile")
```


## Correct for cobbles, boulders and rock

It is assumed that coarse substrates (cobbles, boulders and bedrock) do not contain organic carbon. The predicted stocks therefore have to be corrected based on the assumed fractions of CB and ROCK.

```{r correct_for_cb}
CSF <- (predictors$CB + predictors$ROCK)/100
OCS_corr <- OCS_median * (1 - CSF)
hist(OCS_corr, breaks = 20, main ="", xlab = "Corrected organic carbon stock (kg/m^2)")
plot(OCS_corr)
```

## Reproject

*This is a temporary fix, as long as predictions use the raster package (see above).*

```{r reproject}
OCS_corr <- project(x = OCS_corr, y = "EPSG:25832", res = 50)
OCS_median <- project(x = OCS_median, y = "EPSG:25832", res = 50)
OCS_pi90 <- project(x = OCS_pi90, y = "EPSG:25832", res = 50)
OCS_pir <- project(x = OCS_pir, y = "EPSG:25832", res = 50)
OCS_aoa <- project(x = OCS_aoa$AOA, y = "EPSG:25832", res = 50)
```



## Export results

```{r export_results, message=FALSE, warning=FALSE}
writeRaster(OCS_corr, here("oc_stocks", "data", "ready", "OCS_corr.tif"), overwrite = TRUE)
writeRaster(OCS_median, here("oc_stocks", "data", "ready", "OCS_median.tif"), overwrite = TRUE)
writeRaster(OCS_pi90, here("oc_stocks", "data", "ready", "OCS_pi90.tif"), overwrite = TRUE)
writeRaster(OCS_pir, here("oc_stocks", "data", "ready", "OCS_pir.tif"), overwrite = TRUE)
writeRaster(OCS_aoa, here("oc_stocks", "data", "ready", "OCS_aoa.tif"), overwrite = TRUE)
```


## Output a log file

```{r log}
sink(file = here("oc_stocks", "data", "ready", "model_log.txt"))
model
print("Final Model")
paste0("ME = ", validation[1,1])
paste0("RMSE = ", validation[1,2])
paste0("R2 = ", validation[1,3])
paste0("AOA = ", round(100*fr$count[2]/ sum(fr$count),2), "% of pixels")
sink()
```


